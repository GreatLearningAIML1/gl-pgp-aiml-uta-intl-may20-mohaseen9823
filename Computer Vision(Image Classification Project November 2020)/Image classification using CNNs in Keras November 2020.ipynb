{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ewTFFfS9VP8o"
   },
   "source": [
    "# â€“ Image classification using CNNs in Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyT8x6Cx5ydF"
   },
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "import tensorflow as tf\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.backend import clear_session\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 803,
     "status": "ok",
     "timestamp": 1578416522055,
     "user": {
      "displayName": "Rashi Khanna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDE9tqaJApZNwf0diKaprgyfGdCDJP_OzMjAg8KosA=s64",
      "userId": "05836433031738441465"
     },
     "user_tz": -330
    },
    "id": "8xeywCTPDkA-",
    "outputId": "33e356dc-52d5-4957-a83f-a07c2029e5d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Mounting the google drive\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OB1OfAr8WDdt"
   },
   "outputs": [],
   "source": [
    "#  Converting labels to classes and assigning numbers\n",
    "\n",
    "def classes_to_int(label):\n",
    "    # label = classes.index(directory)\n",
    "    label = label.strip()\n",
    "    if label == \"Black-grass\":  return 0\n",
    "    if label == \"Charlock\":  return 1\n",
    "    if label == \"Cleavers\":  return 2\n",
    "    if label == \"Common Chickweed\":  return 3\n",
    "    if label == \"Common wheat\":  return 4\n",
    "    if label == \"Fat Hen\":  return 5\n",
    "    if label == \"Loose Silky-bent\": return 6\n",
    "    if label == \"Maize\":  return 7\n",
    "    if label == \"Scentless Mayweed\": return 8\n",
    "    if label == \"Shepherds Purse\": return 9\n",
    "    if label == \"Small-flowered Cranesbill\": return 10\n",
    "    if label == \"Sugar beet\": return 11\n",
    "    print(\"Invalid Label\", label)\n",
    "    return 12\n",
    "\n",
    "\n",
    "#  Converting back to labels from numbers\n",
    "\n",
    "def int_to_classes(i):\n",
    "    if i == 0: return \"Black-grass\"\n",
    "    elif i == 1: return \"Charlock\"\n",
    "    elif i == 2: return \"Cleavers\"\n",
    "    elif i == 3: return \"Common Chickweed\"\n",
    "    elif i == 4: return \"Common wheat\"\n",
    "    elif i == 5: return \"Fat Hen\"\n",
    "    elif i == 6: return \"Loose Silky-bent\"\n",
    "    elif i == 7: return \"Maize\"\n",
    "    elif i == 8: return \"Scentless Mayweed\"\n",
    "    elif i == 9: return \"Shepherds Purse\"\n",
    "    elif i == 10: return \"Small-flowered Cranesbill\"\n",
    "    elif i == 11: return \"Sugar beet\"\n",
    "    print(\"Invalid class \", i)\n",
    "    return \"Invalid Class\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-nwShwKDahP"
   },
   "source": [
    "## 1. Read the images and generate the train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-1K0vXYId5Xj"
   },
   "outputs": [],
   "source": [
    "# Extracted the data of Zip file through the commands:\n",
    "#with ZipFile('test.zip', 'r') as z:\n",
    "#  z.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bDBovr6_8gyM"
   },
   "outputs": [],
   "source": [
    "# Opening train folder\n",
    "os.chdir('/content/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1375,
     "status": "ok",
     "timestamp": 1578416592976,
     "user": {
      "displayName": "Rashi Khanna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDE9tqaJApZNwf0diKaprgyfGdCDJP_OzMjAg8KosA=s64",
      "userId": "05836433031738441465"
     },
     "user_tz": -330
    },
    "id": "KKcJh9xJaztb",
    "outputId": "5c8756cd-b340-4847-cf29-f73f1b47a4a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maize',\n",
       " 'Shepherds Purse',\n",
       " 'Fat Hen',\n",
       " 'Common wheat',\n",
       " 'Loose Silky-bent',\n",
       " 'Cleavers',\n",
       " 'Charlock',\n",
       " 'Sugar beet',\n",
       " 'Scentless Mayweed',\n",
       " 'Black-grass',\n",
       " 'Common Chickweed',\n",
       " 'Small-flowered Cranesbill']"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing the contents of the train folder\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89urlDR5nVBI"
   },
   "source": [
    "#### TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7alvTOQE0V8"
   },
   "outputs": [],
   "source": [
    "# Loading all the images, pre-processing them, and storing them in a list of train data\n",
    "\n",
    "def readTrainData(trainDir):\n",
    "    data = []\n",
    "    labels = []\n",
    "    directories = os.listdir() \n",
    "    \n",
    "    for directory in directories:\n",
    "        absDirPath = os.path.join(os.path.sep, trainDir, directory)\n",
    "        images = os.listdir(absDirPath)\n",
    "        \n",
    "        for imageFileName in images:\n",
    "            imageFullPath = os.path.join(trainDir, directory, imageFileName)\n",
    "            img = load_img(imageFullPath)\n",
    "            arr = img_to_array(img)  #Converting image to array\n",
    "            arr = cv2.resize(arr, (128, 128)) #Resizing the array\n",
    "            data.append(arr)\n",
    "            label = classes_to_int(directory)\n",
    "            labels.append(label)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-VxzCIry-0I"
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "X, Y = readTrainData(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVPyK42gHW1t"
   },
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "X = np.array(X, dtype=\"float\") / 255.0\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yl8bZJlvil5B"
   },
   "outputs": [],
   "source": [
    "# Converting the target column to 12 categorical classes\n",
    "Y =  to_categorical(Y, num_classes=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ofJ20ZGnPxy"
   },
   "source": [
    "#### TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0TMIXbL2lZah"
   },
   "outputs": [],
   "source": [
    "# Loading all the images, pre-processing them, and storing them in a list of test data\n",
    "\n",
    "def readTestData(testDir):\n",
    "    data2 = []\n",
    "    filenames = []\n",
    "    images = os.listdir(testDir)\n",
    "    \n",
    "    for imageFileName in images:\n",
    "        imageFullPath = os.path.join(testDir, imageFileName)\n",
    "        img = load_img(imageFullPath)\n",
    "        arr = img_to_array(img)\n",
    "        arr = cv2.resize(arr, (128, 128)) \n",
    "        data2.append(arr)\n",
    "        filenames.append(imageFileName)\n",
    "    return data2, filenames\n",
    "\n",
    "path2 = '/content/gdrive/My Drive/Colab Notebooks/plant-seedlings-classification/test/'\n",
    "X_test, filenames = readTestData(path2)\n",
    "\n",
    "# Scaling the data\n",
    "X_test = np.array(X_test, dtype=\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OYvr5loHHXJq"
   },
   "source": [
    "## 2. Divide the data set into Train and validation data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4BQM1CB3H3qL"
   },
   "outputs": [],
   "source": [
    "# Dividing the data set into train and validation datasets\n",
    "\n",
    "(X_train, X_val, Y_train, Y_val) = train_test_split(X, Y, test_size = 0.3, random_state = 47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kXKk-wROjjvy"
   },
   "source": [
    "## 3. Initialize & build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1213
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2282,
     "status": "ok",
     "timestamp": 1578416678399,
     "user": {
      "displayName": "Rashi Khanna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDE9tqaJApZNwf0diKaprgyfGdCDJP_OzMjAg8KosA=s64",
      "userId": "05836433031738441465"
     },
     "user_tz": -330
    },
    "id": "zTkKvZlJjpH4",
    "outputId": "3d66ae43-e3c5-4c88-8743-bc84402caf80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 128, 128, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8388736   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 8,449,944\n",
      "Trainable params: 8,449,938\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=12)`\n"
     ]
    }
   ],
   "source": [
    "# Clear out tensorflow memory\n",
    "clear_session()\n",
    "\n",
    "# Define Model\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape = (128,128,3)))\n",
    "\n",
    "# 1st Conv Layer\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3), padding=\"same\"))\n",
    "#kernel_initializer = 'he_normal'\n",
    "\n",
    "# Max Pooling layer\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "# Dropout\n",
    "model.add(Dropout(rate = 0.2))\n",
    "\n",
    "# 2nd Conv Layer\n",
    "model.add(Conv2D(filters=64, kernel_size=5, kernel_initializer = 'he_normal', padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Max Pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Dropout\n",
    "model.add(Dropout(rate = 0.2))\n",
    "\n",
    "# Flattening the data\n",
    "model.add(Flatten())\n",
    "\n",
    "# 1st dense layer\n",
    "model.add(Dense(128, kernel_initializer = 'he_normal'))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Dropout\n",
    "model.add(Dropout(rate = 0.3))\n",
    "\n",
    "# 2nd dense layer\n",
    "model.add(Dense(64, kernel_initializer = 'he_normal'))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(output_dim=12, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33435,
     "status": "ok",
     "timestamp": 1578416715684,
     "user": {
      "displayName": "Rashi Khanna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDE9tqaJApZNwf0diKaprgyfGdCDJP_OzMjAg8KosA=s64",
      "userId": "05836433031738441465"
     },
     "user_tz": -330
    },
    "id": "16Axh-CEyVTl",
    "outputId": "36e6b588-d9ec-4399-9641-f26d172fcef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 3325 samples, validate on 1425 samples\n",
      "Epoch 1/10\n",
      "3325/3325 [==============================] - 6s 2ms/step - loss: 2.9496 - acc: 0.1991 - val_loss: 1.9612 - val_acc: 0.4456\n",
      "Epoch 2/10\n",
      "3325/3325 [==============================] - 3s 843us/step - loss: 1.7604 - acc: 0.4553 - val_loss: 1.5154 - val_acc: 0.5404\n",
      "Epoch 3/10\n",
      "3325/3325 [==============================] - 3s 868us/step - loss: 1.3089 - acc: 0.5765 - val_loss: 1.0574 - val_acc: 0.6688\n",
      "Epoch 4/10\n",
      "3325/3325 [==============================] - 3s 862us/step - loss: 0.9829 - acc: 0.6692 - val_loss: 0.9722 - val_acc: 0.6625\n",
      "Epoch 5/10\n",
      "3325/3325 [==============================] - 3s 867us/step - loss: 0.8258 - acc: 0.7224 - val_loss: 0.8658 - val_acc: 0.6947\n",
      "Epoch 6/10\n",
      "3325/3325 [==============================] - 3s 862us/step - loss: 0.6694 - acc: 0.7711 - val_loss: 0.7793 - val_acc: 0.7453\n",
      "Epoch 7/10\n",
      "3325/3325 [==============================] - 3s 875us/step - loss: 0.5211 - acc: 0.8202 - val_loss: 0.7683 - val_acc: 0.7319\n",
      "Epoch 8/10\n",
      "3325/3325 [==============================] - 3s 860us/step - loss: 0.4632 - acc: 0.8376 - val_loss: 0.8594 - val_acc: 0.7102\n",
      "Epoch 9/10\n",
      "3325/3325 [==============================] - 3s 857us/step - loss: 0.3938 - acc: 0.8638 - val_loss: 0.8914 - val_acc: 0.7263\n",
      "Epoch 10/10\n",
      "3325/3325 [==============================] - 3s 857us/step - loss: 0.3060 - acc: 0.8941 - val_loss: 0.8744 - val_acc: 0.7389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f66ac803710>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss and Optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, Y_train, batch_size=60, epochs=10, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hqPRSpHsvZW0"
   },
   "source": [
    "## 4. Optimize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1075
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 99248,
     "status": "ok",
     "timestamp": 1578417163786,
     "user": {
      "displayName": "Rashi Khanna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDE9tqaJApZNwf0diKaprgyfGdCDJP_OzMjAg8KosA=s64",
      "userId": "05836433031738441465"
     },
     "user_tz": -330
    },
    "id": "yjMs-EgSvdHk",
    "outputId": "ef44a8ee-756d-4810-be1f-37bb8bd62a5b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=12)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3325 samples, validate on 1425 samples\n",
      "Epoch 1/30\n",
      "3325/3325 [==============================] - 4s 1ms/step - loss: 2.5108 - acc: 0.2605 - val_loss: 1.9428 - val_acc: 0.3867\n",
      "Epoch 2/30\n",
      "3325/3325 [==============================] - 3s 969us/step - loss: 1.4345 - acc: 0.5239 - val_loss: 1.4968 - val_acc: 0.5396\n",
      "Epoch 3/30\n",
      "3325/3325 [==============================] - 3s 982us/step - loss: 1.0873 - acc: 0.6349 - val_loss: 1.2064 - val_acc: 0.6260\n",
      "Epoch 4/30\n",
      "3325/3325 [==============================] - 3s 993us/step - loss: 0.8161 - acc: 0.7209 - val_loss: 1.2102 - val_acc: 0.6456\n",
      "Epoch 5/30\n",
      "3325/3325 [==============================] - 3s 959us/step - loss: 0.6820 - acc: 0.7678 - val_loss: 0.9933 - val_acc: 0.7193\n",
      "Epoch 6/30\n",
      "3325/3325 [==============================] - 3s 953us/step - loss: 0.5312 - acc: 0.8223 - val_loss: 0.9784 - val_acc: 0.7116\n",
      "Epoch 7/30\n",
      "3325/3325 [==============================] - 3s 947us/step - loss: 0.4383 - acc: 0.8490 - val_loss: 0.9169 - val_acc: 0.7474\n",
      "Epoch 8/30\n",
      "3325/3325 [==============================] - 3s 957us/step - loss: 0.3242 - acc: 0.8911 - val_loss: 0.9440 - val_acc: 0.7481\n",
      "Epoch 9/30\n",
      "3325/3325 [==============================] - 3s 958us/step - loss: 0.2709 - acc: 0.9095 - val_loss: 0.8829 - val_acc: 0.7467\n",
      "Epoch 10/30\n",
      "3325/3325 [==============================] - 3s 977us/step - loss: 0.2590 - acc: 0.9146 - val_loss: 1.0198 - val_acc: 0.7502\n",
      "Epoch 11/30\n",
      "3325/3325 [==============================] - 3s 945us/step - loss: 0.2234 - acc: 0.9251 - val_loss: 1.0048 - val_acc: 0.7621\n",
      "Epoch 12/30\n",
      "3325/3325 [==============================] - 3s 956us/step - loss: 0.2093 - acc: 0.9260 - val_loss: 0.9975 - val_acc: 0.7502\n",
      "Epoch 13/30\n",
      "3325/3325 [==============================] - 3s 955us/step - loss: 0.1833 - acc: 0.9389 - val_loss: 1.0227 - val_acc: 0.7382\n",
      "Epoch 14/30\n",
      "3325/3325 [==============================] - 3s 954us/step - loss: 0.1614 - acc: 0.9498 - val_loss: 1.2466 - val_acc: 0.7495\n",
      "Epoch 15/30\n",
      "3325/3325 [==============================] - 3s 959us/step - loss: 0.1614 - acc: 0.9447 - val_loss: 1.1797 - val_acc: 0.7319\n",
      "Epoch 16/30\n",
      "3325/3325 [==============================] - 3s 967us/step - loss: 0.1702 - acc: 0.9471 - val_loss: 1.2534 - val_acc: 0.7130\n",
      "Epoch 17/30\n",
      "3325/3325 [==============================] - 3s 961us/step - loss: 0.1469 - acc: 0.9558 - val_loss: 1.0008 - val_acc: 0.7691\n",
      "Epoch 18/30\n",
      "3325/3325 [==============================] - 3s 951us/step - loss: 0.0863 - acc: 0.9714 - val_loss: 1.1710 - val_acc: 0.7530\n",
      "Epoch 19/30\n",
      "3325/3325 [==============================] - 3s 957us/step - loss: 0.0838 - acc: 0.9768 - val_loss: 1.1809 - val_acc: 0.7656\n",
      "Epoch 20/30\n",
      "3325/3325 [==============================] - 3s 949us/step - loss: 0.0881 - acc: 0.9702 - val_loss: 1.2597 - val_acc: 0.7607\n",
      "Epoch 21/30\n",
      "3325/3325 [==============================] - 3s 960us/step - loss: 0.0795 - acc: 0.9753 - val_loss: 1.0471 - val_acc: 0.7705\n",
      "Epoch 22/30\n",
      "3325/3325 [==============================] - 3s 962us/step - loss: 0.0640 - acc: 0.9808 - val_loss: 1.1731 - val_acc: 0.7649\n",
      "Epoch 23/30\n",
      "3325/3325 [==============================] - 3s 945us/step - loss: 0.0626 - acc: 0.9808 - val_loss: 1.3530 - val_acc: 0.7796\n",
      "Epoch 24/30\n",
      "3325/3325 [==============================] - 3s 957us/step - loss: 0.0634 - acc: 0.9832 - val_loss: 1.1650 - val_acc: 0.7923\n",
      "Epoch 25/30\n",
      "3325/3325 [==============================] - 3s 948us/step - loss: 0.0576 - acc: 0.9805 - val_loss: 1.3638 - val_acc: 0.7523\n",
      "Epoch 26/30\n",
      "3325/3325 [==============================] - 3s 963us/step - loss: 0.0825 - acc: 0.9720 - val_loss: 1.3562 - val_acc: 0.7495\n",
      "Epoch 27/30\n",
      "3325/3325 [==============================] - 3s 969us/step - loss: 0.0731 - acc: 0.9741 - val_loss: 1.4182 - val_acc: 0.7565\n",
      "Epoch 28/30\n",
      "3325/3325 [==============================] - 3s 953us/step - loss: 0.0606 - acc: 0.9808 - val_loss: 1.4430 - val_acc: 0.7425\n",
      "Epoch 29/30\n",
      "3325/3325 [==============================] - 3s 951us/step - loss: 0.0655 - acc: 0.9762 - val_loss: 1.4016 - val_acc: 0.7551\n",
      "Epoch 30/30\n",
      "3325/3325 [==============================] - 3s 945us/step - loss: 0.0743 - acc: 0.9768 - val_loss: 1.5287 - val_acc: 0.7326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6525e3cf60>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear out tensorflow memory\n",
    "clear_session()\n",
    "\n",
    "# Define Model\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape = (128,128,3)))\n",
    "\n",
    "# 1st Conv Layer\n",
    "model.add(Conv2D(32, (3,3), input_shape=(128, 128, 3)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# Max Pooling layer\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "# Dropout\n",
    "model.add(Dropout(rate = 0.2))\n",
    "\n",
    "# 2nd Conv Layer\n",
    "model.add(Conv2D(filters=64, kernel_size=5, padding=\"same\"))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# Max Pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Dropout\n",
    "model.add(Dropout(rate = 0.2))\n",
    "\n",
    "# Flattening the data\n",
    "model.add(Flatten())\n",
    "\n",
    "# 1st dense layer\n",
    "model.add(Dense(128, kernel_initializer = 'he_normal'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# Dropout\n",
    "model.add(Dropout(rate = 0.3))\n",
    "\n",
    "# 2nd dense layer\n",
    "model.add(Dense(64, kernel_initializer = 'he_normal'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# 3rd dense layer\n",
    "model.add(Dense(32, kernel_initializer = 'he_normal'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(output_dim=12, activation = 'softmax'))\n",
    "\n",
    "# Loss and Optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, Y_train, batch_size=60, epochs=30, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pgalPb3QvgEa"
   },
   "source": [
    "## 5. Predict the accuracy for both train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "18xVaSjZvh5Y"
   },
   "outputs": [],
   "source": [
    "Y_predict1 = model.predict(X_val)\n",
    "Y_predict2 = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1214,
     "status": "ok",
     "timestamp": 1578417312665,
     "user": {
      "displayName": "Rashi Khanna",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDE9tqaJApZNwf0diKaprgyfGdCDJP_OzMjAg8KosA=s64",
      "userId": "05836433031738441465"
     },
     "user_tz": -330
    },
    "id": "BmzZl218zMhh",
    "outputId": "c839a13d-95ad-45a5-f717-0e12bd578a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of validation data is 73.26\n",
      "The accuracy of train data is 99.88\n"
     ]
    }
   ],
   "source": [
    "# Finding the accuracy:\n",
    "\n",
    "accuracy1 = accuracy_score(Y_val.argmax(axis=1), Y_predict1.argmax(axis=1))\n",
    "print(\"The accuracy of validation data is\", round(accuracy1*100, 2))\n",
    "\n",
    "accuracy2 = accuracy_score(Y_train.argmax(axis=1), Y_predict2.argmax(axis=1))\n",
    "print(\"The accuracy of train data is\", round(accuracy2*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "og2AsriV_s6d"
   },
   "outputs": [],
   "source": [
    "# the Accuaracy of Validation data is 73.26 percent\n",
    "# where as the Accuracy of train data is 99.88 percent\n",
    "# Hence we can say that this predicts better in classifying the given images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ComputerVisionWithCNN_R7_Project1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
